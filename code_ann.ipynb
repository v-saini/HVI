{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAwVl7Dc2u48"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.offsetbox import AnchoredText\n",
        "import matplotlib.colors as colors\n",
        "from mpl_toolkits import mplot3d\n",
        "from math import sqrt\n",
        "import warnings\n",
        "\n",
        "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split,KFold,cross_val_score,GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder,LabelEncoder, MinMaxScaler\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, ElasticNet\n",
        "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,ExtraTreesRegressor,BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.models import load_model\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "plt.rcParams['savefig.dpi'] = 600\n",
        "plt.rcParams[\"savefig.format\"] = 'tiff'\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axkjJPmA20AE"
      },
      "outputs": [],
      "source": [
        "sns.set(style='whitegrid')\n",
        "sns.set_context(\"paper\", font_scale=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujXS1gGh3791"
      },
      "outputs": [],
      "source": [
        "# Learning Rate Scheduler\n",
        "def scheduler(epoch, lr):\n",
        "  if epoch < 160:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * np.exp(-0.1)\n",
        "\n",
        "callback = keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "\n",
        "\n",
        "# Neural Network\n",
        "def Neural_network():\n",
        "    init = keras.initializers.random_normal()\n",
        "    model=Sequential()\n",
        "    model.add(layers.Dense(64,activation=keras.layers.LeakyReLU(alpha=0.3),kernel_initializer=init, input_dim=scaled_DF.shape[1]))\n",
        "    model.add(layers.Dropout(0.1))\n",
        "    \n",
        "\n",
        "    model.add(layers.Dense(32,activation=keras.layers.LeakyReLU(alpha=0.3),kernel_initializer=init))\n",
        "    model.add(layers.Dropout(0.1))\n",
        "\n",
        "    \n",
        "    # model.add(layers.Dense(128,activation=keras.layers.LeakyReLU(alpha=0.3),kernel_initializer=init))\n",
        "    # model.add(layers.Dropout(0.1))\n",
        "\n",
        "    \n",
        "    model.add(layers.Dense(1,kernel_initializer=init,activation = 'linear'))\n",
        " \n",
        "    \n",
        "    optimize=tf.keras.optimizers.Adam()\n",
        "    \n",
        "    model.compile(optimizer=optimize,\n",
        "                    loss='mse',\n",
        "                    )\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_j7T0KwQ372z"
      },
      "outputs": [],
      "source": [
        "# Funtion to train the model\n",
        "def training_model(X_train,Y_train,model):\n",
        "    history=model.fit(X_train,Y_train,epochs=200,batch_size=64,verbose=0,callbacks=[callback])\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4khWM6037vD"
      },
      "outputs": [],
      "source": [
        "# To print losses\n",
        "def plots():\n",
        "    f, ax = plt.subplots(1,1)\n",
        "    actual_test=np.array(scaler.inverse_transform(testY).reshape(-1,1))\n",
        "    predicted_test=np.array(scaler.inverse_transform(model.predict(testX).reshape(-1,1)))\n",
        "\n",
        "\n",
        "    actual=np.array(scaler.inverse_transform(np.array(trainY).reshape(-1,1)))\n",
        "    predicted=np.array(scaler.inverse_transform(model.predict(np.array(trainX)).reshape(-1,1)))\n",
        "\n",
        "    plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "    plt.rcParams['savefig.dpi'] = 600\n",
        "    plt.rcParams[\"savefig.format\"] = 'tiff'\n",
        "\n",
        "    sns.set(style='whitegrid')\n",
        "    sns.set_context(\"paper\", font_scale=2)\n",
        "\n",
        "    sns.regplot(actual_test,predicted_test, color='olivedrab', scatter_kws={'s':75, 'alpha':0.8, 'edgecolor':'black'})\n",
        "\n",
        "\n",
        "    print(\"Mean absolute error (MAE):      %f\" % mean_absolute_error(actual_test,predicted_test))\n",
        "    print(\"Mean squared error (MSE):       %f\" % mean_squared_error(actual_test,predicted_test))\n",
        "    print(\"Root mean squared error (RMSE): %f\" % sqrt(mean_squared_error(actual_test,predicted_test)))\n",
        "    print(\"R square (R^2):                 %f\" % r2_score(actual_test,predicted_test))\n",
        "    \n",
        "    \n",
        "    plt.xlabel('BDE (Actual)')\n",
        "    plt.ylabel('Predicted')\n",
        "\n",
        "    anchored_text = AnchoredText(\"R\\u00b2 Score_test = \"+str(round(r2_score(actual_test,predicted_test),3)) +'\\n'\"MAE = \"+str(round(mean_absolute_error(actual_test,predicted_test),2)), loc=2,prop=dict(size=15))\n",
        "    ax.add_artist(anchored_text)\n",
        "    \n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(str(model)[1:6], bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyJVio7i37fE"
      },
      "outputs": [],
      "source": [
        "def defining_model(x):\n",
        "    if x=='rndmfrst':\n",
        "      model = RandomForestRegressor()\n",
        "    else:\n",
        "      print(\"wrong selection\")\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ndFsEvtD8Yf"
      },
      "outputs": [],
      "source": [
        "# Getting data from CSV file\n",
        "train = pd.read_excel('train.xlsx')\n",
        "test = pd.read_excel('test.xlsx')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine Train and test for feature engineering\n",
        "DF_raw = pd.concat([train,test],ignore_index=True)\n",
        "DF_data = DF_raw.copy()"
      ],
      "metadata": {
        "id": "T-PlJHDEg6HW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DF_data.drop(['Smiles_1','inchi'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "iDfbDxRXgiWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b71TS-7jIsHE"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Scaling the whole DataFrame\n",
        "\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled_DF = pd.DataFrame(scaler.fit_transform(DF_data.iloc[:,1:]))\n",
        "scaled_DF.columns = DF_data.iloc[:,1:].columns\n",
        "\n",
        "scaled_DF['BDE'] = scaler.fit_transform(np.array(DF_data['BDE']).reshape(-1,1))\n",
        "scaled_DF\n",
        "\n",
        "display(scaled_DF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTN0ycy4MTeB"
      },
      "outputs": [],
      "source": [
        "DF_target = scaled_DF[['BDE']]\n",
        "scaled_DF.drop('BDE',axis=1,inplace=True)\n",
        "\n",
        "display(DF_data)\n",
        "display(DF_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Wt0tdLX666B"
      },
      "outputs": [],
      "source": [
        "trainX = scaled_DF[:len(train)] \n",
        "testX = scaled_DF[len(train):]\n",
        "\n",
        "trainY = DF_target[:len(train)]\n",
        "testY = DF_target[len(train):]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainX.shape"
      ],
      "metadata": {
        "id": "91JIth64a-Ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "de2qXFRURQMS"
      },
      "outputs": [],
      "source": [
        "# Random Forest\n",
        "model = defining_model(x = 'rndmfrst')\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "\n",
        "scores = []\n",
        "rmse = []\n",
        "for train,valid in kfold.split(trainX,trainY):\n",
        "  model.fit(trainX.iloc[train],trainY.iloc[train])\n",
        "  scores.append(model.score(trainX.iloc[valid],trainY.iloc[valid]))\n",
        "  actual = trainY.iloc[valid]\n",
        "  predicted = model.predict(trainX.iloc[valid])\n",
        "  rmse.append(sqrt(mean_squared_error(scaler.inverse_transform(actual),scaler.inverse_transform(predicted.reshape(-1,1)))))\n",
        "\n",
        "print(\"Average validation R2 score after crossvalidation : \", np.mean(scores))\n",
        "print(\"Average validation rmse score after crossvalidation : \", np.mean(rmse))\n",
        "\n",
        "\n",
        "# Train model on whole train data\n",
        "model = defining_model(x = 'rndmfrst')\n",
        "model.fit(trainX,trainY)\n",
        "plots()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# get importance\n",
        "importance = model.feature_importances_\n",
        "# summarize feature importance\n",
        "dicts = {\n",
        "    'Feature':[x for x in trainX.columns],\n",
        "    'Importance':importance\n",
        "    }\n",
        "DF_imp = pd.DataFrame(dicts)\n",
        "DF_imp = DF_imp.sort_values('Importance',ascending=False)\n",
        "DF_imp.to_excel('imp.xlsx', index=None)\n",
        "\n",
        "# plot feature importance\n",
        "plt.bar('Feature','Importance',data = DF_imp.iloc[:6,:])\n",
        "plt.xticks(rotation = 90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_UdBuW-u5EYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zAshpwmuQDO"
      },
      "outputs": [],
      "source": [
        "model = Neural_network()\n",
        "\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=None)\n",
        "\n",
        "best_score = 0.1\n",
        "\n",
        "scores = []\n",
        "rmse = []\n",
        "for train,valid in kfold.split(trainX,trainY):\n",
        "  training_model(trainX.iloc[train],trainY.iloc[train],model)\n",
        "  scores.append(r2_score(trainY.iloc[valid],model.predict(trainX.iloc[valid])))\n",
        "  \n",
        "  actual = trainY.iloc[valid]\n",
        "  predicted = model.predict(trainX.iloc[valid])\n",
        "  rmse.append(sqrt(mean_squared_error(scaler.inverse_transform(actual),scaler.inverse_transform(predicted))))\n",
        "    \n",
        "print(\"Average validation R2 score after crossvalidation : \", np.mean(scores))\n",
        "print(\"Average validation rmse score after crossvalidation : \", np.mean(rmse))\n",
        "\n",
        "# Train model on whole train data\n",
        "\n",
        "model = Neural_network()\n",
        "training_model(trainX,trainY,model)\n",
        "#actual = trainY\n",
        "#predicted = model.predict(trainX)\n",
        "\n",
        "actual=np.array(scaler.inverse_transform(np.array(trainY)))\n",
        "predicted=np.array(scaler.inverse_transform(model.predict(np.array(trainX)).reshape(-1,1)))\n",
        "model.save(\"nn.h5\")\n",
        "score = r2_score(actual,predicted)\n",
        "print(\"\\n\\nTraining Accuracy : \",score) # Training Accuracy\n",
        "plots()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('nn.h5')"
      ],
      "metadata": {
        "id": "8I8AjMVI8lRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plots()"
      ],
      "metadata": {
        "id": "8ImggJQCCKir"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}